{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "080adea5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 64\u001b[0m\n\u001b[0;32m     62\u001b[0m train_raw \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput/train.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     63\u001b[0m test_raw  \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput/test.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 64\u001b[0m train_fe \u001b[38;5;241m=\u001b[39m engineer_features(train_raw, is_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     65\u001b[0m test_fe \u001b[38;5;241m=\u001b[39m engineer_features(test_raw, is_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Mục tiêu\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 45\u001b[0m, in \u001b[0;36mengineer_features\u001b[1;34m(df, is_train)\u001b[0m\n\u001b[0;32m     43\u001b[0m out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCompanions\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTicketFreq\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mclip(lower\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Fare per person + bins\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFare\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFare\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;241m0\u001b[39m, np\u001b[38;5;241m.\u001b[39mnan)\n\u001b[0;32m     46\u001b[0m denom \u001b[38;5;241m=\u001b[39m out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFamilySize\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     47\u001b[0m out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFarePerPerson\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFare\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m denom\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# ==== FE nâng cao + Stacking để tăng điểm Kaggle ====\n",
    "import re\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.base import clone\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "# 1) Feature engineering nâng cao\n",
    "\n",
    "def extract_title(name: str) -> str:\n",
    "    if pd.isna(name):\n",
    "        return \"Unknown\"\n",
    "    m = re.search(r\" ([A-Za-z]+)\\.\", str(name))\n",
    "    if not m:\n",
    "        return \"Unknown\"\n",
    "    title = m.group(1)\n",
    "    mapping = {\n",
    "        'Mlle': 'Miss', 'Ms': 'Miss', 'Mme': 'Mrs',\n",
    "        'Lady': 'Rare', 'the Countess': 'Rare', 'Capt': 'Rare', 'Col': 'Rare',\n",
    "        'Don': 'Rare', 'Dr': 'Rare', 'Major': 'Rare', 'Rev': 'Rare',\n",
    "        'Sir': 'Rare', 'Jonkheer': 'Rare', 'Dona': 'Rare'\n",
    "    }\n",
    "    return mapping.get(title, title)\n",
    "\n",
    "def engineer_features(df: pd.DataFrame, is_train: bool = True) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    # Cabin/Deck\n",
    "    out['Deck'] = out['Cabin'].fillna('U').astype(str).str[0]\n",
    "    # Gia đình\n",
    "    out['FamilySize'] = out.get('SibSp', 0) + out.get('Parch', 0) + 1\n",
    "    out['IsAlone'] = (out['FamilySize'] == 1).astype(int)\n",
    "    out['FamilyCat'] = pd.cut(out['FamilySize'], bins=[0,1,3,4,20], labels=['Singleton','Small','Medium','Large'], include_lowest=True)\n",
    "    # Title\n",
    "    out['Title'] = out['Name'].apply(extract_title)\n",
    "    # Vé\n",
    "    out['TicketLen'] = out['Ticket'].astype(str).str.len()\n",
    "    out['TicketFreq'] = out.groupby('Ticket')['Ticket'].transform('count')\n",
    "    out['Companions'] = (out['TicketFreq'] - 1).clip(lower=0)\n",
    "    # Fare per person + bins\n",
    "    out['Fare'] = out['Fare'].replace(0, np.nan)\n",
    "    denom = out['FamilySize'].replace(0, 1)\n",
    "    out['FarePerPerson'] = out['Fare'] / denom\n",
    "    out['FareCat'] = pd.qcut(out['Fare'].fillna(out['Fare'].median()), q=8, labels=False, duplicates='drop')\n",
    "    # Age bins\n",
    "    out['AgeBin'] = pd.cut(out['Age'], bins=[-1,5,12,18,30,45,60,80,120], labels=False)\n",
    "    # Vai trò\n",
    "    out['SexNum'] = (out['Sex'] == 'male').astype(int)\n",
    "    out['IsChild'] = ((out['Age'] < 16).astype(float)).fillna(0).astype(int)\n",
    "    out['IsMother'] = ((out['Sex'] == 'female') & (out.get('Parch', 0) > 0) & (out['Title'] != 'Miss')).astype(int)\n",
    "    # Tương tác đơn giản\n",
    "    if 'Pclass' in out.columns:\n",
    "        out['AgeTimesClass'] = out['Age'].fillna(out['Age'].median()) * out['Pclass']\n",
    "        out['FareTimesClass'] = out['Fare'].fillna(out['Fare'].median()) * out['Pclass']\n",
    "    return out\n",
    "\n",
    "# Tạo bản FE cho train/test gốc (đã có biến train, test trước đó)\n",
    "train_raw = pd.read_csv('input/train.csv')\n",
    "test_raw  = pd.read_csv('input/test.csv')\n",
    "train_fe = engineer_features(train_raw, is_train=True)\n",
    "test_fe = engineer_features(test_raw, is_train=False)\n",
    "\n",
    "# Mục tiêu\n",
    "y = train_fe['Survived'].astype(int)\n",
    "X = train_fe.drop(columns=['Survived'])\n",
    "X_submit = test_fe.copy()\n",
    "\n",
    "# 2) Preprocess\n",
    "numeric_cols = [c for c in X.columns if X[c].dtype != 'object']\n",
    "categorical_cols = [c for c in X.columns if X[c].dtype == 'object']\n",
    "preprocess = ColumnTransformer([\n",
    "    ('num', Pipeline([\n",
    "        ('imp', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ]), numeric_cols),\n",
    "    ('cat', Pipeline([\n",
    "        ('imp', SimpleImputer(strategy='most_frequent')),\n",
    "        ('oh', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "    ]), categorical_cols)\n",
    "])\n",
    "\n",
    "# 3) Base models\n",
    "rf = RandomForestClassifier(n_estimators=800, max_depth=10, random_state=42, n_jobs=-1)\n",
    "gx = xgb.XGBClassifier(n_estimators=900, max_depth=5, learning_rate=0.03, subsample=0.8, colsample_bytree=0.8,\n",
    "                        tree_method='hist', eval_metric='logloss', n_jobs=-1, random_state=42)\n",
    "gb = GradientBoostingClassifier(n_estimators=400, learning_rate=0.05, max_depth=3, random_state=42)\n",
    "\n",
    "pipes = [\n",
    "    Pipeline([('pp', preprocess), ('mdl', rf)]),\n",
    "    Pipeline([('pp', preprocess), ('mdl', gx)]),\n",
    "    Pipeline([('pp', preprocess), ('mdl', gb)])\n",
    "]\n",
    "\n",
    "# 4) OOF stacking\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "oof_list = [np.zeros(len(X)) for _ in pipes]\n",
    "test_pred_list = [np.zeros(len(X_submit)) for _ in pipes]\n",
    "\n",
    "for tr_idx, va_idx in cv.split(X, y):\n",
    "    X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "    y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "    for i, base in enumerate(pipes):\n",
    "        m = clone(base)\n",
    "        m.fit(X_tr, y_tr)\n",
    "        oof_list[i][va_idx] = m.predict_proba(X_va)[:, 1]\n",
    "        test_pred_list[i] += m.predict_proba(X_submit)[:, 1] / cv.get_n_splits()\n",
    "\n",
    "OOF = np.vstack(oof_list).T\n",
    "TEST = np.vstack(test_pred_list).T\n",
    "\n",
    "# 5) Meta-learner + threshold tuning\n",
    "meta = xgb.XGBClassifier(n_estimators=250, max_depth=3, learning_rate=0.08, subsample=0.9, colsample_bytree=0.9,\n",
    "                         tree_method='hist', eval_metric='logloss', random_state=42, n_jobs=-1)\n",
    "meta.fit(OOF, y)\n",
    "oof_proba = meta.predict_proba(OOF)[:, 1]\n",
    "\n",
    "def tune_threshold(y_true, proba):\n",
    "    best_thr, best_acc = 0.5, 0.0\n",
    "    for thr in np.linspace(0.3, 0.7, 81):\n",
    "        pred = (proba >= thr).astype(int)\n",
    "        acc = (pred == y_true.values).mean()\n",
    "        if acc > best_acc:\n",
    "            best_acc, best_thr = acc, thr\n",
    "    return best_thr, best_acc\n",
    "\n",
    "thr, acc = tune_threshold(y, oof_proba)\n",
    "print(f\"OOF acc(meta): {acc:.4f} | best thr: {thr:.3f}\")\n",
    "\n",
    "# 6) Dự đoán test và xuất submission\n",
    "TEST_PROBA = meta.predict_proba(TEST)[:, 1]\n",
    "preds = (TEST_PROBA >= thr).astype(int)\n",
    "sub = pd.DataFrame({'PassengerId': test_raw['PassengerId'], 'Survived': preds.astype(int)})\n",
    "sub.to_csv('submission_stacked.csv', index=False)\n",
    "print('Saved submission_stacked.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
